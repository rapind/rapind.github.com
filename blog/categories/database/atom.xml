<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Database | Dave Rapin]]></title>
  <link href="http://rapind.github.com/blog/categories/database/atom.xml" rel="self"/>
  <link href="http://rapind.github.com/"/>
  <updated>2015-10-17T13:08:35-04:00</updated>
  <id>http://rapind.github.com/</id>
  <author>
    <name><![CDATA[Dave Rapin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Handling Customer Addresses for Relational Purchasing]]></title>
    <link href="http://rapind.github.com/blog/2011/03/20/handling-customer-addresses-for-relational-purchasing/"/>
    <updated>2011-03-20T15:16:00-04:00</updated>
    <id>http://rapind.github.com/blog/2011/03/20/handling-customer-addresses-for-relational-purchasing</id>
    <content type="html"><![CDATA[<p>A problem I often run into whenver I build an ordering system is how best to store addresses for customers and orders in an ordering system (like an ecommerce store).</p>

<p>Given the following conditions for an order placement application:</p>

<ul>
<li>Customer's can register and supply seperate billing and shipping addresses.</li>
<li>Orders need to store customer data as a snapshot of when the order was placed in case the customer data is changed or removed in the future (orders should maintain historical integrity).</li>
</ul>


<p>We have several different ways of accomplishing this with a relational database (document and KV stores are a different story).</p>

<ol>
<li><p>Store all address information within the customer and order tables themselves. This is perhaps the easiest solution even though it's not the most normalized. So you'd have fields like billing_city and shipping_city inside both the customers and the orders tables. The downside is that you've created duplicates of the same fields, which uses up a little more storage space (usually not an issue) and requires more work to maintain if you ever needed to change their schema (again, pretty rare occurence for address fields that are well known entities). The upside is it's very simple to work with from a code perspective.</p></li>
<li><p>Store addresses in their own table and associate them to orders and customers using via polymorphic composite keys. In order for this to work you'll need a composite key of 3 fields; address_type, addressable_type, addressable_id. So the shipping address for a customer would be something like: "Shipping", "Customer", 1232. and the billing address for an order could be: "Billing", "Order", 2873. etc. The downside is it's a rather fancy assoication and will add complexity to your ORM code as you override some methods (since no ORM I know of is built to handle this oddball relationship out of the box). The upside is it's very normalized and you can add new address types on the fly and new classes that can have addresses on the fly.</p></li>
<li><p>Store addresses in their own table, but simplify the association by using many-to-one foreign keys. For this to work we just have keys in the address table for each assoication. So in this case we have "billing_customer_id", "shipping_customer_id", "billing_order_id", "shipping_order_id". The downside is it's not very normalized / DRY and you won't be able to add new address types or addressable classes on the fly like you could using the plymorphic associations. The upside is very simple (almost all convention based) ORM code since you're dealing with belongs_to type relationships.</p></li>
<li><p>Use an Address class to define your address fields, but serialize it to text fields wherever it's used. So you're ditching the relational style just for the addresses. For this to work you'd have two text fields in your orders table and your customers table; "billing_address" and "shipping_address". Then you just serialize your address objects to these fields (yaml, xml, json, or whatever). The upside is the same simplicity as solution #1, but without all of the redundancy in your schema. The downside is the potential complexity of code needed to edit and manage the address information and get proper validations to work.</p></li>
</ol>


<p>My preferred solution is #4. I think it's worth the added complexity at the view level when using Rails 3 since it's not too much extra work (although it could be a little cleaner).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Backing up your MySQL Databases Offsite]]></title>
    <link href="http://rapind.github.com/blog/2010/05/06/backing-up-your-mysql-databases-offsite/"/>
    <updated>2010-05-06T08:40:00-04:00</updated>
    <id>http://rapind.github.com/blog/2010/05/06/backing-up-your-mysql-databases-offsite</id>
    <content type="html"><![CDATA[<p>I recently came across a nifty little tool called Tarsnap.</p>

<p>From the Tarsnap home page:</p>

<p>Tarsnap is a secure online backup service for BSD, Linux, OS X, Solaris, Cygwin, and can probably be compiled on many other UNIX-like operating systems. The Tarsnap client code provides a flexible and powerful command-line interface which can be used directly or via shell scripts.</p>

<p>Here's a quick and easy guide to get you up and running backup up all of your MySQL databases.</p>

<h3>Automate the MySQL Backup</h3>

<ol>
<li><p>In your home directory:
<code>
mkdir backups &amp;&amp; cd backups
</code></p></li>
<li><p>Download: <a href="http://sourceforge.net/projects/automysqlbackup/">http://sourceforge.net/projects/automysqlbackup/</a> to the backups directory you just created.</p></li>
<li><p>Rename it:
<code>
mv automysqlbackup.sh.2.5 automysqlbackup.sh
</code></p></li>
<li><p>Make it executable:
<code>
chmod u+rwx automysqlbackup.sh
</code></p></li>
<li><p>Edit it:
<code>
nano automysqlbackup.sh
</code></p></li>
<li><p>Fill out your database name, password, and the names of the databases you want to backup.</p></li>
<li><p>Look for the commented POSTBACKUP line. Add these two lines right below it (replace username with your username).
<code>
BACKUP_TIMESTAMP=$(date +"%m-%d-%Y_%T")
POSTBACKUP="tarsnap -c -f databases.$BACKUP_TIMESTAMP /home/username/backups"
</code></p></li>
</ol>


<h3>Install and Setup Tarsnap.</h3>

<ol>
<li><p>Follow the instructions on the Tarsnap getting started page: <a href="http://www.tarsnap.com/gettingstarted.html">http://www.tarsnap.com/gettingstarted.html</a></p></li>
<li><p>You should have donwloaded, paid for, and installed Tarsnap before continuing.</p></li>
<li><p>We're going to use the tarsnap sample config (cache dir and key location).
<code>
cd /usr/local/etc
cp tarsnap.conf.sample tarsnap.conf
</code></p></li>
<li><p>Now run your backup script:
<code>
sudo ./automysqlbackup.sh
</code></p></li>
<li><p>Check to see if you're backup was created and stored remotely:
<code>
sudo tarsnap --list-archives
</code></p></li>
<li><p>Now we're going to create a cronjob to run the script on a daily basis (or you could move it to your /etc/cron.daily).
```
sudo crontab -e</p>

<h1>backup the databases every day at 2:30 AM</h1>

<p>30 2 * * * /home/deploy/backups/automysqlbackup.sh > /home/deploy/cron.log
```</p></li>
</ol>


<p>Now you're databases are being backed up daily on a rotation keeping weekly and monthly dumps and storing them both on and off-site (encrypted).</p>
]]></content>
  </entry>
  
</feed>
